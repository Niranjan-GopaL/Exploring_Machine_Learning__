{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c8e1f",
   "metadata": {},
   "source": [
    "# Setting Up the Environmetn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "44388e01-60d4-40f4-8b38-a0e5059b3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   sklearn.preprocessing import StandardScaler,PolynomialFeatures \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6fd243ec-c637-4925-91ac-70bbb685a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688bb93-b53e-4346-b7e2-c3e3ba4aacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69578c6e-08f2-4354-9015-149814886c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_x = dataset.drop(\"mpg\",axis=1)\n",
    "f1=dataset[\"Feature1\"]\n",
    "f2=dataset[\"Feature2\"]\n",
    "f3=dataset[\"Feature3\"]\n",
    "f4=dataset[\"Feature4\"]\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8224e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = dataset.drop(\"Label\",axis=1)\n",
    "dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1569240-4986-42e0-a6df-edd5b8a55015",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset[\"Label\"]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5508462-47e3-44f7-bc88-83fd3b368858",
   "metadata": {},
   "source": [
    "## Exporatory Data Analysis\n",
    "\n",
    "( try proving that none of the features can be modeled using Linear Regression Convincingly )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f5daa-01de-4228-a992-2238db8d99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc115c6-3529-4195-aa40-bf907c96487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e47ffb",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "1. **Removing Null values**: \n",
    "   - All rows with missing values were dropped. \n",
    "\n",
    "2. **Converting Bool to 0 or 1**:\n",
    "   - `Feature2` was converted to numeric (0 or 1) for model compatibility.\n",
    "\n",
    "3. **Removing Outlier**: \n",
    "   - Any entry with a Z score more than a certain threshold ( = 2 ) was conisdered an outlier and was dropped.\n",
    "\n",
    "4. **Feature Scaling**:\n",
    "   - Features were scaled using `StandardScaler` to ensure proper model performance.\n",
    "\n",
    "5. **Splitting train data into train and validation partition**:\n",
    "   - `train_data_x`   split into `train_data_x` and `validation_data_x` respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27498a48-3b97-43cd-874d-485a0e2e10ea",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6f149840",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f958a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_x.dropna()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6c5c4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c2b728e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, z_thresh=2):\n",
    "    z_scores = np.abs((df - df.mean()) / df.std()) \n",
    "    return df[(z_scores < z_thresh).all(axis=1)]\n",
    "\n",
    "X = remove_outliers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526684f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.loc[X.index]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "89ff2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2, random_state=543)\n",
    "X_train_standardized = scaler.fit_transform(X=X_train)\n",
    "X_test_standardized = scaler.fit_transform(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d4d8b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d9b078e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0025a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_polynomial = poly.fit_transform(X_train)\n",
    "X_test_polynomial  = poly.transform(X_test)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_polynomial_transformed = scaler.fit_transform(X_train_polynomial)\n",
    "X_test_polynomial_transformed  = scaler.transform(X_test_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b41031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train_standardized)\n",
    "    X_val_poly = poly.transform(X_test_standardized)\n",
    "    \n",
    "    #for each degree 3 cases -> normal, ridge and lasso\n",
    "    models = {\n",
    "        'Polynomial Regression': LinearRegression(),\n",
    "        'Ridge Regression':      Ridge(alpha=0.001),\n",
    "        'Lasso Regression':      Lasso(alpha=0.01)\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_name = ''\n",
    "    \n",
    "    #for all 3 cases, we calculate mse whichever is the lowest MSE, we return the best model\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_poly, Y_train)\n",
    "        y_val_pred = model.predict(X_val_poly)\n",
    "        val_mse = mean_squared_error(Y_test, y_val_pred)\n",
    "        print(f'{name} (degree {degree}) Validation MSE: {val_mse}')\n",
    "        \n",
    "        if val_mse < best_mse:\n",
    "            best_model = model\n",
    "            best_mse = val_mse\n",
    "            best_name = name\n",
    "    \n",
    "    return best_model, poly, best_mse, best_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8050404",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1,2, 3, 4, 5, 6, 7, 8]\n",
    "best_overall_model = None\n",
    "best_overall_poly = None\n",
    "best_overall_mse = float('inf')\n",
    "best_overall_name = ''\n",
    "best_degree = 0\n",
    "\n",
    "#iterate over all degrees from 1 to 5 and then among the best models for that degree, we find the best model (again with overall lowest mse)\n",
    "for degree in degrees:\n",
    "    best_model, best_poly, best_mse, best_name = evaluate_models(degree)\n",
    "    if best_mse < best_overall_mse:\n",
    "        best_overall_model = best_model\n",
    "        best_overall_poly = best_poly\n",
    "        best_overall_mse = best_mse\n",
    "        best_overall_name = best_name\n",
    "        best_degree = degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09f45f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f19f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Model: {best_overall_name} (degree {best_degree})')\n",
    "print(f'Best Model Validation MSE: {best_overall_mse}')\n",
    "\n",
    "test_dataset = pd.read_csv(\"test.csv\")\n",
    "test_dataset_x = test_dataset.drop(\"id\",axis=1)\n",
    "test_X = test_dataset_x.dropna()\n",
    "X_test_standardized = scaler.fit_transform(X=test_X)\n",
    "\n",
    "# Transform the test data using the best polynomial model\n",
    "test_poly = best_overall_poly.transform(X_test_standardized)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = best_overall_model.predict(test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a02484b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting predictions in file as per expected format \n",
    "ids = [i for  i in range(len(test_dataset)) ]\n",
    "submission = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'Label': test_predictions\n",
    "})\n",
    "submission.to_csv('IMT2022543_submission_11.csv',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
